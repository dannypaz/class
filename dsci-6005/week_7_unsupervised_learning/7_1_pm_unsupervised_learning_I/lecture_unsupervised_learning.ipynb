{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unsupervised Learning & Autoencoders\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://blog.venturesity.com/wp-content/uploads/2015/06/clustering.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Explain the difference Supervised & Unsupervised Learning\n",
    "- List examples of Unsupervised Learning\n",
    "- Define and diagram an Autoencoder\n",
    "- Explain practical applications for Autoencoders\n",
    "- List limitations of Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is Unsupervised Learning (UL)?\n",
    "------\n",
    "<br>\n",
    "<center><img src=\"http://oliviaklose.azurewebsites.net/content/images/2015/02/2-supervised-vs-unsupervised-1.png\" height=\"500\"/></center>\n",
    "\n",
    "Given inputs, find \"interesting patterns\" in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "aka, Descriptive Learning or Knowledge Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "------\n",
    "\n",
    "What is the best error metric (e.g., accuracy, precision, recall,‚Ä¶) for UL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__None__. There is no appropriate error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Framing Unsupervised Learning\n",
    "------\n",
    "\n",
    "Density estimation\n",
    "\n",
    "Build models with the form: p(x|Œ∏)\n",
    "\n",
    "x is the data and Œ∏ is a generative function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "------\n",
    "\n",
    "If unsupervised learning is p(x|Œ∏), what is supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "p(y|x,Œ∏)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If Supervised Learning p(y|x,Œ∏) is __conditional__ density estimation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unsupervised Learning p(x|Œ∏)is __unconditional__ density estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "----\n",
    "\n",
    "During the RL lecture, I use a cake metaphor for RL, SL, and UL.\n",
    "\n",
    "If RL is the cherry, what is the icing and the cake?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let them eat cake üç∞! \n",
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*KDvA9Fq3lm-eQOyGlcKAKg.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: Dmytro (Dima) Lituiev (UCSF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Supervised Learning\n",
    "------\n",
    "\n",
    "<center><img src=\"images/tiger_supervised.png\" height=\"500\"/></center>\n",
    "\n",
    "Given: features\n",
    "\n",
    "Task: predict target/label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Autoencoders (AE)\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/tiger_autoencoder.png\" height=\"500\"/></center>\n",
    "\n",
    "- Only features, no label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Learn a representation from features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classifer Analogy\n",
    "----\n",
    "<br>\n",
    "\n",
    "<center><img src=\"images/supervised_kid.png\" height=\"500\"/></center>\n",
    "\n",
    "A kid learning to pick out object name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Autoencoders Analogy\n",
    "----- \n",
    "<br>\n",
    "<center><img src=\"images/unsupervised_kid.png\" height=\"500\"/></center>\n",
    "\n",
    "Drawing picture from memory or retelling a story by heart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are autoencoders (AE) good for?\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Dimensionality reduction, especially for data visualization\n",
    "- Compression\n",
    "- Feature extraction\n",
    "- Data denoising / noise reduction\n",
    "- Anomaly detection \n",
    "- Pattern generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE Pattern generation\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/ugly_sweaters.png\" height=\"500\"/></center>\n",
    "\n",
    "[source: Stitchfix Blog](source: http://multithreaded.stitchfix.com/assets/images/blog/random_shirts3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What other DL architecture can generate  realistic reconstructions of images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"http://www.kdnuggets.com/wp-content/uploads/generative-adversarial-network.png\" width=\"500\"/></center>\n",
    "\n",
    "GANs often perform better than AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "------\n",
    "\n",
    "<center><img src=\"images/w2v_neural_net_blank.png\" height=\"500\"/></center>\n",
    "\n",
    "Where else in the gU curriculum have you seen AE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "word2vec is an Autoencoder\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/w2v_neural_net.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE are \"fancy\": They have \"bow-ties\" üéÄ\n",
    "------\n",
    "\n",
    "<center><img src=\"http://2.bp.blogspot.com/-xdfotR5CIoY/VjJ7UKrFP2I/AAAAAAAAFlM/sHI4T4j0IrY/s1600/autoencoders.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE for data compression\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://static.squarespace.com/static/531f2c4ee4b002f5b011bf00/t/536bdcefe4b03580f8f6bb16/1399577848961/hbosiliconvalleypiedpiperoldlogo\" height=\"500\"/></center>\n",
    "\n",
    "1. Data specific\n",
    "2. Lossy\n",
    "3. Learned automatically from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Autoencoders are data specific\n",
    "------\n",
    "\n",
    "Only able to compress data similar to what AE have been trained on. Feature weights do not generalize across domains.\n",
    "\n",
    "Our AE trained on tigers üêØ won't do well on faces üë©.\n",
    "\n",
    "Different from other compression algorithms (i.e., mp3) which is rule-based and can compress any domain within a data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Autoencoders are lossy\n",
    "------\n",
    "\n",
    "Decompressed outputs will be degraded compared to the original inputs.\n",
    "\n",
    "In contrast to lossless arithmetic compression (e.g., zip files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. Autoencoders Learned automatically from data\n",
    "-------\n",
    "\n",
    "We ‚ù§Ô∏è machine learning!\n",
    "\n",
    "Easy to train specialized AE instances.\n",
    "\n",
    "AE does __not__ require any new rules, just training data and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://blog.keras.io/building-autoencoders-in-keras.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Are AE useful for data compression?\n",
    "------\n",
    "\n",
    "Usually, not really. üòû\n",
    "\n",
    "Autoencoders are data-specific. Thus, generally impractical for real-world data compression problems.\n",
    "\n",
    "But if you have specific data (e.g., words) then use AE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maybe in the future this limitation will be overcome. ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE Parts List\n",
    "------\n",
    "\n",
    "<center><img src=\"images/tiger_autoencoder.png\" height=\"500\"/></center>\n",
    "\n",
    "You need three things: \n",
    "\n",
    "1. An encoding function\n",
    "2. A decoding function\n",
    "3. A distance / loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE Formalism\n",
    "-----\n",
    "\n",
    "| Concept | Symbol |  \n",
    "|:-------|:------:|\n",
    "| original data | x |\n",
    "| encoder | h(x) |  \n",
    "| encoding or \"hidden/latent state\" | z = h(x) |  \n",
    "| decoder (g for generator) | g(‚ãÖ) |  \n",
    "| reconstruction | r = g(z) |  \n",
    "| encoder | h(x) |  \n",
    "| idenitity mapping | r = g(h(x)) ‚âà x |\n",
    "| reconstruction error | MSE: L(r, x) = ‚à£‚à£r ‚àí x‚à£‚à£<sup>2</sup> |\n",
    "| constraint loss (optional) i.e. L1 norm for sparsity | C(z) = ‚àë ‚à£z<sub>i</sub>‚à£ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE architecture\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://ufldl.stanford.edu/tutorial/images/Autoencoder636.png\" width=\"450\"/></center>\n",
    "\n",
    "The autoencoder tries to learn a function:  \n",
    "h<sub>W,b</sub>(x) ‚âà x.\n",
    "\n",
    "In other words, it is trying to learn an approximation to the identity function, so as to output xÃÇ that is similar to x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE Learning\n",
    "-----\n",
    "\n",
    "Minimize distance between the amount of information __loss__ between the compressed representation of your data and the decompressed representation.\n",
    "\n",
    "Total loss = Reconstruction error + Constraint loss \n",
    "\n",
    "Minimize the loss by Stochastic Gradient Descent(SGD) (or different flavor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE structure\n",
    "------\n",
    "\n",
    "<center><img src=\"images/tiger_autoencoder.png\" height=\"500\"/></center>\n",
    "\n",
    "Remember AE tries to learn the identity function (relatively trivial) \n",
    "\n",
    "But by placing constraints on the network we can discover interesting structure about the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE constraints\n",
    "-----\n",
    "\n",
    "1. Limit the number of hidden units\n",
    "2. L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By having fewer hidden states (nodes) than the input dimensionality, AE creates a \"undercomplete representation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/auto3.png\" width=\"500\"/></center>\n",
    "\n",
    "How many input dimensions are there?  \n",
    "How many compressed dimensions are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are inputs 4 dimensions that are compressed to 2 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "------\n",
    "<center><img src=\"images/same.png\" height=\"500\"/></center>\n",
    "What if there is an __equal__ number of input, hidden, and output nodes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is no compression. \n",
    "\n",
    "The AE learns the identity function. Same data and out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "------\n",
    "<center><img src=\"images/more.png\" height=\"500\"/></center>\n",
    "What if there are __more__ hidden nodes than input output nodes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The NN learns to map the data to different parts of hidden without minimal reuse of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE architecture\n",
    "-----\n",
    "\n",
    "1. Encoder\n",
    "2. Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Encoder\n",
    "------\n",
    "\n",
    "<center><img src=\"images/encoder.png\" height=\"500\"/></center>\n",
    "\n",
    "Compresses a multi-dimensional observed data sample to a hidden / latent representation of the data\n",
    "\n",
    "The hidden representation is low-dimensional or otherwise constrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Decoder\n",
    "------\n",
    "\n",
    "<center><img src=\"images/decoder.png\" height=\"500\"/></center>\n",
    "\n",
    "Unpacks / interprets / decompresses the hidden / latent representation into the __reconstruction__ of a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://cdn-images-1.medium.com/max/1000/1*j_y0bNZLP1yzqtyF48Z3Ug.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AE are NOT unsupervised (I've mislead you)\n",
    "------\n",
    "\n",
    "<center><img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\" height=\"500\"/></center>\n",
    "\n",
    "AE are a __self-supervised__ technique.\n",
    "\n",
    "Self-supervised: A type of supervised learning where the targets are generated from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Skip-gram architecture for word2vec is self-supervised\n",
    "------\n",
    "\n",
    "<center><img src=\"images/skip-gram.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "------\n",
    "\n",
    "What is the difference between a MLP and an AE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The output of AE has to be the same size as the input. A MLP output is often much smaller.\n",
    "<center><img src=\"https://qph.ec.quoracdn.net/main-qimg-82b1a05b73274bc412f629d8e035af30.webp\" height=\"500\"/></center>\n",
    "[Source](https://www.quora.com/What-is-the-difference-between-a-neural-network-and-an-autoencoder-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Stacked Autoencoders: We must go Deeper!\n",
    "------\n",
    "\n",
    "<center><img src=\"images/stacked.png\" height=\"500\"/></center>\n",
    "\n",
    "A stacked autoencoder is a neural network consisting of multiple layers of sparse autoencoders in which the outputs of each layer is wired to the inputs of the successive layer.\n",
    "\n",
    "[Learn more here](http://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "----\n",
    "\n",
    "- Unsupervised Learning learns useful representations of data without labels.\n",
    "- Autoencoders (AE) can be considered a variation of Unsupervised Learning.\n",
    "- AE are often used to compress data. But they have limited applications.\n",
    "- AE consist of 3 parts:\n",
    "    1. Encoder\n",
    "    2. Decoder\n",
    "    3. Distance function\n",
    "- AE tries to learn the identity mapping but constraints prevent it\n",
    "    - Reduced number of hidden nodes\n",
    "    - Regularization: Typically L1 \n",
    "- AE are just another variation of NN with the requirement to have equal number of input and output nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Bonus Material\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Variational Autoencoders (VAEs)\n",
    "------\n",
    "\n",
    "The mathematical basis of VAEs actually has relatively little to do with\n",
    "classical autoencoders, e.g. sparse autoencoders or denoising autoencoders\n",
    "\n",
    "P(X) = Intregal:P(X|z; Œ∏)P(z)dz\n",
    "\n",
    "VAEs approximately maximize the equation above according to a plate model.\n",
    "\n",
    "They are called ‚Äúautoencoders‚Äù only because the final training objective that derives from this setup does have an encoder and a decoder, and resembles a traditional autoencoder.\n",
    "\n",
    "[Source](https://arxiv.org/pdf/1606.05908.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Restricted Boltzmann Machines & Deep Belief Network\n",
    "-----\n",
    "\n",
    "- Not currently used in applied settings\n",
    "- Deep Belief Networks are stacked Restricted Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
