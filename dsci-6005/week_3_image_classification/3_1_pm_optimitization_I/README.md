Optimitization, I
----

__Introductory__:

- [Backpropagation as an analogy for understanding gradient descent](https://en.wikipedia.org/wiki/Backpropagation#An_analogy_for_understanding_gradient_descent)
- [Jupyter Notebook demos of optimitzation 1](https://github.com/jermwatt/mlrefined/blob/master/2.1_Basic_optimization_demos.ipynb)
- [Jupyter Notebook demos of optimitzation 2](https://github.com/jermwatt/mlrefined/blob/master/3.1_Regression_optimization_demos.ipynb)

__Required__:

- [Types of optimitizers](https://deeplearning4j.org/updater)
- Read Chapter 4 "Beyond Gradient Descent" from _Fundamentals of Deep Learning_ book
- Read Chapter 8 "Optimitization for Training Deep Models" from _Deep Learning_ book

__Optional__:

- [An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/)

__Challenge__:

- [Opt algos in ML](http://videolectures.net/nips2010_wright_oaml/)
- Convex Optimization by Boyd and Vendernberghe