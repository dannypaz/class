{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement SGD\n",
    "-----\n",
    "\n",
    "Based on this [package](https://hackage.haskell.org/package/sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Stochastic gradient descent implementation using mutable vectors for efficient update of the parameters vector. \n",
    "\n",
    "A user is provided with the immutable vector of parameters so he is able to compute the gradient outside of the IO monad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "{-# LANGUAGE RecordWildCards #-}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "module Numeric.SGD\n",
    "( SgdArgs (..)\n",
    ", sgdArgsDefault\n",
    ", Para\n",
    ", sgd\n",
    ", module Numeric.SGD.Grad\n",
    ", module Numeric.SGD.Dataset\n",
    ") where\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "import           Control.Monad (forM_)\n",
    "import qualified System.Random as R\n",
    "import qualified Data.Vector.Unboxed as U\n",
    "import qualified Data.Vector.Unboxed.Mutable as UM\n",
    "import qualified Control.Monad.Primitive as Prim\n",
    "\n",
    "import           Numeric.SGD.Grad\n",
    "import           Numeric.SGD.Dataset\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "-- | SGD parameters controlling the learning process.\n",
    "data SgdArgs = SgdArgs\n",
    "    { -- | Size of the batch\n",
    "      batchSize :: Int\n",
    "    -- | Regularization variance\n",
    "    , regVar    :: Double\n",
    "    -- | Number of iterations\n",
    "    , iterNum   :: Double\n",
    "    -- | Initial gain parameter\n",
    "    , gain0     :: Double\n",
    "    -- | After how many iterations over the entire dataset\n",
    "    -- the gain parameter is halved\n",
    "    , tau       :: Double }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "-- | Default SGD parameter values.\n",
    "sgdArgsDefault :: SgdArgs\n",
    "sgdArgsDefault = SgdArgs\n",
    "    { batchSize = 30\n",
    "    , regVar    = 10\n",
    "    , iterNum   = 10\n",
    "    , gain0     = 1\n",
    "    , tau       = 5 }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "-- | A stochastic gradient descent method.\n",
    "-- A notification function can be used to provide user with\n",
    "-- information about the progress of the learning.\n",
    "-- TODO: Implement this method\n",
    "\n",
    "sgd\n",
    "    :: SgdArgs                  -- ^ SGD parameter values\n",
    "    ->                          -- ^ Notification run every update\n",
    "    ->                          -- ^ Gradient for dataset element\n",
    "    ->                          -- ^ Dataset\n",
    "    ->                          -- ^ Starting point\n",
    "    ->                          -- ^ SGD result\n",
    "sgd SgdArgs{..} notify mkGrad dataset x0 = do\n",
    "    u <- UM.new (U.length x0)\n",
    "    doIt u 0 (R.mkStdGen 0) =<< U.thaw x0\n",
    "where\n",
    "    -- Gain in k-th iteration.\n",
    "    gain k =  \n",
    "\n",
    "    -- Number of completed iterations over the full dataset.\n",
    "    done k\n",
    "        = fromIntegral (k * batchSize)\n",
    "        / fromIntegral (size dataset)\n",
    "\n",
    "    doIt u k stdGen x\n",
    "      | done k > iterNum = do\n",
    "        frozen <- U.unsafeFreeze x\n",
    "        notify frozen k\n",
    "        return frozen\n",
    "      | otherwise = do\n",
    "        (batch, stdGen') <- sample stdGen batchSize dataset\n",
    "\n",
    "        -- Freeze mutable vector of parameters. The frozen version is\n",
    "        -- then supplied to external mkGrad function provided by user.\n",
    "        frozen <- U.unsafeFreeze x\n",
    "        notify frozen k\n",
    "\n",
    "        -- let grad = M.unions (map (mkGrad frozen) batch)\n",
    "        let grad = parUnions (map (mkGrad frozen) batch)\n",
    "        addUp grad u\n",
    "        scale (gain k) u\n",
    "\n",
    "        x' <- U.unsafeThaw frozen\n",
    "        apply u x'\n",
    "        doIt u (k+1) stdGen' x'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "-- | Add up all gradients and store results in normal domain.\n",
    "addUp :: Grad -> MVect -> IO ()\n",
    "addUp grad v = do\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
