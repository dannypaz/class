{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimization II\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://s2.quickmeme.com/img/7c/7c31a1bd26ee70da803b5223ecf3d270ef8ba94711c8a9d74ef21e84571d317c.jpg\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Describe the fundamentals of optimization and Stochastic Gradient Descent (SGD) \n",
    "- Define the following concepts:\n",
    "    - Momentum\n",
    "    - Decay\n",
    "    - Adaptive Learning Rate\n",
    "- Describe Keras' built-in optimization algorithms:\n",
    "    - Adagrad & Adadelta\n",
    "    - RMSprop\n",
    "    - Adam, Adamax, & Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimization I Review\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is a simple, nontechnical definition of optimization?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Find the best solution to a given problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is optimization in computer programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://ls12-www.cs.tu-dortmund.de/daes/images/stories/research/c2c/optlevel.png\" height=\"500\"/></center>\n",
    "\n",
    "Code that does what it is suppose to do with minimal use of resources (e.g., time, memory, or space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is optimization in machine learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://image.slidesharecdn.com/slides-150310074926-conversion-gate01/95/apsis-automatic-hyperparameter-optimization-framework-for-machine-learning-4-638.jpg?cb=1425973828\" height=\"500\"/></center>\n",
    "\n",
    "Find the best set of parameters and hyperparameters for the function(s), given the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some branches of optimization have guaranteed optimal solutions, do we want this in DL? Why or why not?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"http://replycandy.com/wp-content/uploads/Godzilla-Nope-Response-Meme.jpg\" height=\"500\"/></center>\n",
    "\n",
    "1. We do not have the time given the number of dimensions and possible values.\n",
    "2. We might over fit / memorize!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the workhorse solution for DL optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"images/sgd.png\" height=\"500\"/></center>\n",
    "Mini-Batch Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://www.bogotobogo.com/python/scikit-learn/images/Batch-vs-Stochastic-Gradient-Descent/stochastic-vs-batch-gradient-descent.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Learning Rate Decay\n",
    "----\n",
    "\n",
    "<center><img src=\"https://qph.ec.quoracdn.net/main-qimg-f3972c89625c0451f0ea92a4c0ea0728\" height=\"500\"/></center>\n",
    "\n",
    "Learning rate decay over each update, slow down learning over time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Momentum\n",
    "----\n",
    "\n",
    "<center><img src=\"images/mom.png\" height=\"500\"/></center>\n",
    "\n",
    "Minimizes the zig-zagging by applying knowledge from previous steps to guide where the optimizer should go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is Momentum useful?\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://www.yaldex.com/game-development/FILES/17fig09.gif\" height=\"500\"/></center>\n",
    "\n",
    "- __Accelerator__: Builds up speed in directions with a gentle but consistent gradient.\n",
    "- __Smoother__:Damps oscillations in directions of high curvature by combining gradients with opposite signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nesterov momentum\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/nes.png\" height=\"500\"/></center>\n",
    "\n",
    "1. First make a big jump in the direction of the previous accumulated gradient.\n",
    "2. Then measure the gradient where you end up and make a correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Keras Optimizers](https://keras.io/optimizers/)\n",
    "-----\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c9/Keras_Logo.jpg\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other [Keras Optimizers](https://keras.io/optimizers/)\n",
    "-----\n",
    "\n",
    "- Adagrad & Adadelta\n",
    "- RMSprop\n",
    "- Adam, Adamax, & Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adagrad (Adaptive Gradient)\n",
    "-----\n",
    "\n",
    "Adaptive technique for learning rate updates\n",
    "\n",
    "Updates individual weights differently depending on how frequently they change.\n",
    "\n",
    "Scales each parameter according to the history of gradients (previous steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adagrad (Adaptive Gradient)\n",
    "-----\n",
    "\n",
    "Like\"tf-idf\" for learning weights: Performing larger updates for infrequent and smaller updates for frequent parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example: Adagrad can be used to train word embeddings, as infrequent words require much larger updates than frequent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does Adagrad work?\n",
    "------\n",
    "\n",
    "<center><img src=\"images/updater_math3.png\" width=\"500\"/></center>\n",
    "\n",
    "Basically done by dividing the current gradient in the update rule by the sum of previous gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__NOTE__: `g` is 2<sup>nd</sup> order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adagrad: Take home message\n",
    "-----\n",
    "\n",
    "__Upside__: Useful for sparse data, where it assigns a higher learning rate to infrequently updated parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Downside__: For long running training, eventually all gradients diminish. Its accumulation of the squared gradients in the denominator: Since every added term is positive, the accumulated sum keeps growing during training. Learning rate becomes infinitesimally small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adadelta\n",
    "-----\n",
    "\n",
    "Like Adagrad (weights updated by historical gradients), however weights updated by exponentially decaying the average.\n",
    "\n",
    "Creating a bounded historical window for weight updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adadelta\n",
    "-----\n",
    "\n",
    "<center><img src=\"https://deeplearning4j.org/img/updater_math8.png\" width=\"500\"/></center>\n",
    "[Source](https://deeplearning4j.org/updater)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the difference between Adagrad and Adadelta?\n",
    "------\n",
    "\n",
    "Adagrad is more sensitive to hyperparameters and may decrease the learning rate too aggressively.\n",
    "\n",
    "Adadelta is often an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "RMSprop\n",
    "-----\n",
    "\n",
    "<center><img src=\"https://deeplearning4j.org/img/updater_math5.png\" height=\"500\"/></center>\n",
    "<center><img src=\"https://deeplearning4j.org/img/updater_math6.png\" height=\"500\"/></center>\n",
    "<center><img src=\"https://deeplearning4j.org/img/updater_math7.png\" height=\"500\"/></center>\n",
    "Like Adadelta (exponentially decaying the average), RMSprop also includes momentum.\n",
    "\n",
    "Essentially \"normalizes\" the gradient by dividing by the magnitude of recent gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "RMSprop\n",
    "-----\n",
    "\n",
    "When a plateau in the error surface is encountered and the gradient is very small, the updates take greater steps, ensuring faster learning   \n",
    "(a small update: 0.00001, the square root of the weighted average: 0.00005, update size: 0.2). \n",
    "\n",
    "Also, RMSprop protects against exploding gradients  \n",
    "(a large update: 100, the square root of the weighted average: 25, update size: 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "RMSprop could help which DL architectures that have issues with vanishing and exploding gradients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__RNNs and LSTMs__ \n",
    "\n",
    "RNNs and LSTMs suffer from vanishing and exploding gradients because of Backpropagation through time (BPTT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sorry there aren't a lot of images for this kinda optimization\n",
    "------\n",
    "<br>\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/optimization.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adam (Adaptive Moment Estimation)\n",
    "-----\n",
    "\n",
    "Stores an exponentially decaying average of past squared gradients like Adadelta and RMSprop.\n",
    "\n",
    "Also keeps an exponentially decaying average of past gradients, similar to momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adam (Adaptive Moment Estimation)\n",
    "-----\n",
    "\n",
    "<center><img src=\"https://deeplearning4j.org/img/updater_math9.png\" width=\"400\"/></center>\n",
    "\n",
    "m and g are estimates of the first moment (the mean) and the second moment (the uncentered variance) of the gradients respectively, hence the name of the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adamax \n",
    "-----\n",
    "\n",
    "Variant of Adam based on the infinity norm (the maximum of the absolute values of components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Does any one happen to know what the \"Infinity Norm\" is?\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"images/inf.png\" width=\"700\"/></center>\n",
    "\n",
    "The maximum of the absolute values of components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nadam\n",
    "-----\n",
    "\n",
    "Adam RMSprop with Nesterov momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparing optimizers behavior: Speed of finding simple minimum  \n",
    "----\n",
    "\n",
    "<center><img src=\"http://2.bp.blogspot.com/-q6l20Vs4P_w/VPmIC7sEhnI/AAAAAAAACC4/g3UOUX2r_yA/s400/s25RsOr%2B-%2BImgur.gif\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparing optimizers behavior: Speed of finding not simple minimum  \n",
    "----\n",
    "\n",
    "<center><img src=\"http://cs231n.github.io/assets/nn3/opt2.gif\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparing optimizers behavior: Escaping saddle points\n",
    "----\n",
    "\n",
    "<center><img src=\"http://cs231n.github.io/assets/nn3/opt1.gif\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Okay which optimizers should i use?\n",
    "-----\n",
    "\n",
    "1) It doesn't matter for applied problems, just pick a decent optimizer. Architectures, data, and time are more important. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2) Empirical question: If you have time, find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3) Otherwise: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"http://cdn.emgn.com/wp-content/uploads/2015/09/Addams-Family-Trivia-EMGN3.jpg\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Show me the metadata: Adam wins\n",
    "----\n",
    "\n",
    "<center><img src=\"images/over_time.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "-----\n",
    "\n",
    "- Optimitization - Do it. \n",
    "- Optimitization - Don't spend too much time on it.\n",
    "- SGD is good baseline\n",
    "- Update learning rates more if they are updated less often (Adagrad)\n",
    "- \"Normalize\" gradients with exponentially decaying average and momentum (RMSprop)\n",
    "- Exponentially decay __both__ average and momentum (Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
