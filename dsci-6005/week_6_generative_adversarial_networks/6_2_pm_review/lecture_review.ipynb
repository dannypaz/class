{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://static.fjcdn.com/pictures/Homer+goes+to+college_e70fae_5473925.jpg\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Combing RNN and CNN for images: Wait for next week\n",
    "-----\n",
    "<br>\n",
    "<center><img src=\"http://s2.quickmeme.com/img/b0/b0c74b951ed34baa8313635d8a5121665d22d8c5e30d85dcfe326863a8c929fe.jpg\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN\n",
    "----\n",
    "\n",
    "<center><img src=\"images/rnn.png\" height=\"500\"/></center>\n",
    "\n",
    "The gradient signal is multiplied a large number of times (as many as the number of timesteps) by the weight matrix associated with the connections between the neurons of the recurrent hidden layer. \n",
    "\n",
    "This means that, the magnitude of weights in the transition matrix can have a strong impact on the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/unrolled.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://avisingh599.github.io/images/vqa/lstm_encoder.jpg\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are three types of gates within a LSTM unit:\n",
    "\n",
    "1. Forget Gate: Conditionally decides what information to throw away from the block.\n",
    "2. Input Gate: Conditionally decides which values from the input to update the memory state.\n",
    "3. Output Gate: Conditionally decides what to output based on input and the memory of the block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each unit is like a mini-state machine where the gates of the units have weights that are learned during the training procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the components of time series?\n",
    "-------\n",
    "\n",
    "<center><img src=\"images/time.png\" height=\"500\"/></center>\n",
    "\n",
    "- Seasonal / Cyclic\n",
    "- Trend / Drift\n",
    "- Irregular / Remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "LSTM can learn to predict the next steps based on long-term dependencies\n",
    "-----\n",
    "<center><img src=\"images/time.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/172145096\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x102468710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import VimeoVideo\n",
    "VimeoVideo(\"172145096\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Demo](http://lstm.seas.harvard.edu/client/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](http://lstm.seas.harvard.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://cdn-images-1.medium.com/max/1600/1*qq32JuituQW8dANNvwbiwQ.png\" height=\"500\"/></center>\n",
    "\n",
    "[Visualizing LSTM in Keras](https://medium.com/@plusepsilon/visualizations-of-recurrent-neural-networks-c18f07779d56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
