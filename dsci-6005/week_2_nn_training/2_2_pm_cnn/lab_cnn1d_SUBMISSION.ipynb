{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning Objectives\n",
    "\n",
    "By the end of this lab, you will have\n",
    "\n",
    "- Implemented Convolution, ReLU, and Max-Pooling layers\n",
    "- Created a reusable convolutional block layer\n",
    "- Verfied the correctness of your implementations with gradient checking\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Layer Interface\n",
    "\n",
    "Recall when implementing a layer to make it conform to the following interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def forward(self, inputs):\n",
    "        raise NotImplementedError('Forward pass not implemented!')\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        raise NotImplementedError('Backward pass not implemented!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Max-Pooling Layer\n",
    "\n",
    "Consider a 1D Max-Pooling layer described by the computational graph\n",
    "\n",
    "![Simple Max Pooling Layer](images/Simple%20Max%20Pooling%20Layer.png)\n",
    "where\n",
    "\n",
    "$$\n",
    "z = \\max(\\mathbf{h}).\n",
    "$$\n",
    "\n",
    "### Questions\n",
    "\n",
    "- How many dimensions in $\\nabla_h$ will be non-zero assuming there is a unique $h_i$ such that $h_i = \\max(\\mathbf{h})$?\n",
    "- What if there are two values $h_i$ and $h_j$ such that $h_i = h_j = \\max(\\mathbf{h})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max pooling = max( 4x4 region)\n",
    "# for a one dimensional array, there will only be one max. Therefore, there will be N-1 dimensions that are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.array([1,2,3,4,5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Max_Pool(Layer):\n",
    "    def forward(self,h):\n",
    "        self.h = h\n",
    "        z = max(h)\n",
    "        \n",
    "        self.z = z if z > 0 else 0\n",
    "        return z\n",
    "    def backward(self,incoming_grad ):\n",
    "        dz = incoming_grad\n",
    "        if self.z >0:\n",
    "            dh = 1\n",
    "        else:\n",
    "            dh = 0\n",
    "        return dh * dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_pool = Max_Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool.forward(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool.backward(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tasks\n",
    "\n",
    "- Implement a 1D Max-Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ReLU Layer\n",
    "\n",
    "Consider the ReLU layer described by the computational graph\n",
    "\n",
    "![Simple ReLU Layer](images/Simple%20ReLU%20Layer.png)\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_{i} = \n",
    "\\begin{cases} \n",
    "0 & \\text{if } \\mathbf{a}_{i} \\leq 0 \\\\\n",
    "\\mathbf{a}_{i} & \\text{otherwise}\n",
    "\\end{cases}.\n",
    "$$\n",
    "\n",
    "### Questions\n",
    "\n",
    "- What will $\\nabla_a$ be if $a_i < 0$ for all $i$?\n",
    "- What if $a_i > 0$ for all $i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tasks\n",
    "\n",
    "- Implement a 1D ReLU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Layer\n",
    "\n",
    "Consider a 1D convolution layer with a single filter $w$ described by the computational graph\n",
    "\n",
    "![Simple Conv1D Layer](images/Simple%20Conv1D%20Layer.png)\n",
    "where $a_i = w * x_i$. Note since $w \\in \\mathbb{R}$, we are performing a 1x1 convolution. Further assume that we are only dealing with a stride of 1.\n",
    "\n",
    "### Questions\n",
    "\n",
    "- How many elements in $\\mathbf{a}$ does $x_i$ influence?\n",
    "- How many elements in $\\mathbf{a}$ does $w$ influence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# How many elements in  a  does  xi  influence?\n",
    "## Xi will only influence one element in a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tasks\n",
    "\n",
    "- Implement a 1D convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Convolution_Layer_scalar(Layer):\n",
    "    def forward(self,x,w):\n",
    "        self.x = x\n",
    "        self.w=w\n",
    "        convolution = [i*w for i in x]\n",
    "        return convolution\n",
    "    def backward(self,incoming_grad):\n",
    "        da = incoming_grad\n",
    "        dw = self.x * da\n",
    "        dx = self.w * da\n",
    "        return dw,dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1,4,2,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convolution_layer = Convolution_Layer_scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 40, 20, 50, 30]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_layer.forward(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 4, 2, 5, 3]), 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_layer.backward(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "{\\displaystyle {\\begin{aligned}(f*g_{N})[n]&=\\sum _{m=0}^{N-1}f[m]\\ g_{N}[n-m]\\\\&=\\sum _{m=0}^{n}f[m]\\ g[n-m]+\\sum _{m\\,=\\,n+1}^{N-1}f[m]\\ g[N+n-m]\\\\&=\\sum _{m=0}^{N-1}f[m]\\ g[(n-m)_{\\bmod {N}}]\\equiv (f*_{N}g)[n]\\end{aligned}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e36dcdb8325f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Convolution_Layer_vectors(Layer):\n",
    "    def forward(self,x,w,convolution_padding=1):\n",
    "        self.x = x\n",
    "        self.w=w\n",
    "        convolution = np.zeros(len(self.x)+convolution_padding)\n",
    "\n",
    "        for y_number in range(len(x)+convolution_padding):\n",
    "            \n",
    "            convolution_sum = 0\n",
    "            for x_idx in range(y_number+1):\n",
    "                print(x_idx,'x_idx')\n",
    "                print(y_number-x_idx,\"y_number-x_idx\")\n",
    "                try:\n",
    "                    convolution_sum += x[x_idx]*w[y_number-x_idx]\n",
    "                except IndexError: ## no weights left\n",
    "                    pass\n",
    "            print(\"convolution sum is {}\".format(convolution_sum))\n",
    "            convolution[y_number]=convolution_sum\n",
    "        self.convolution = convolution\n",
    "        return convolution\n",
    "    def backward(self,incoming_grad):\n",
    "        pass # Full derivation available online\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([3,4,5])\n",
    "w = np.array([2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_lay_vec = Convolution_Layer_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x_idx\n",
      "0 y_number-x_idx\n",
      "convolution sum is 6\n",
      "0 x_idx\n",
      "1 y_number-x_idx\n",
      "1 x_idx\n",
      "0 y_number-x_idx\n",
      "convolution sum is 11\n",
      "0 x_idx\n",
      "2 y_number-x_idx\n",
      "1 x_idx\n",
      "1 y_number-x_idx\n",
      "2 x_idx\n",
      "0 y_number-x_idx\n",
      "convolution sum is 14\n",
      "0 x_idx\n",
      "3 y_number-x_idx\n",
      "1 x_idx\n",
      "2 y_number-x_idx\n",
      "2 x_idx\n",
      "1 y_number-x_idx\n",
      "3 x_idx\n",
      "0 y_number-x_idx\n",
      "convolution sum is 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  6.,  11.,  14.,   5.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_lay_vec.forward(x,w,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolutional Block\n",
    "\n",
    "- Consider a convolutional block layer described by the computational graph\n",
    "\n",
    "$$\n",
    "\\underset{w \\in \\mathbb{R}}{\\overset{\\mathbf{x} \\in \\mathbb{R}^N}{\\longrightarrow}}\n",
    "\\text{Conv}\n",
    "\\longrightarrow\n",
    "\\text{ReLU}\n",
    "\\longrightarrow\n",
    "\\text{Max Pool}\n",
    "\\overset{h \\in \\mathbb{R}}{\\longrightarrow}\n",
    "$$\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Implement a convolutional block layer in terms of Convolutional, ReLU, and Max Pool layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check Your Implementation\n",
    "\n",
    "An indispensible tool to check your backpropagation code is *gradient checking*. Gradient checking works by\n",
    "\n",
    "1. Running your backward pass to compute the gradients\n",
    "2. Approximating the gradients with finite differences\n",
    "3. Compares these two values and returns success if they are close and fails otherwise\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Run the following code cell to gradient check your convolutional block\n",
    "\n",
    "### Explanation\n",
    "\n",
    "- The code will create a vector $x$ of five random numbers and a random filter $w$. It approxiates $\\nabla{x}$ and $\\nabla{w}$ and compares those values against the values of $\\nabla{w}$ and $\\nabla{x}$ your `ConvBlock.backward()` method returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus Activities\n",
    "\n",
    "- Implement a 1D convolution layer with support for multiple scalar filters\n",
    "- Implement a 1D convolution layer with one filter which is a vector\n",
    "- Implement a 1D convolution layer with a set of filters which are vectors\n",
    "- Implement a 2D convolution layer\n",
    "- Implement a max-pooling layer which supports local maxes\n",
    "- Implement a 2D max-pooling layer\n",
    "- Generalize your code to support minibatches\n",
    "- Implement a simple trainer class with an SGD optimizer and optimize a CNN on MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
