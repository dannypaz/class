{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9049\n",
      "5 0.9125\n",
      "10 0.9143\n",
      "15 0.9165\n",
      "20 0.9179\n",
      "25 0.9186\n"
     ]
    }
   ],
   "source": [
    "# AdaGrad solution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mnistReader import mnist\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = mnist()\n",
    "\n",
    "tf.reset_default_graph() \n",
    "g = tf.Graph() \n",
    "with g.as_default():\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, 784]) # effectively the first layer; minibatch_size by 784 matrix\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, 10]) # true image class. this is a one-hot coded matrix, minibatch_size by 10\n",
    "\n",
    "    lr = tf.constant(0.2, dtype=tf.float32, name='lr')\n",
    "    weight_shape = [784, 10] # weight matrix shape for weight matrix between 1st and 2nd layer\n",
    "    [n_inputs, n_outputs] = weight_shape\n",
    "    init_range = sqrt(6.0 / (n_inputs + n_outputs))  #from glorot paper\n",
    "    #Pick one of the following initializations for weights: idea is neural net to train faster\n",
    "    w = tf.Variable(tf.random_normal(weight_shape, stddev=0.01), name='w')   #avant de -glorot\n",
    "    #w = tf.Variable(tf.random_uniform(weight_shape, -init_range, init_range), name='w')   #apres glorot\n",
    "\n",
    "    #define network\n",
    "    logits = tf.matmul(X, w) # matrix multiplication between 1st and 2nd layer, minibatch_size by 10 matrix \n",
    "    py_x = tf.nn.softmax(logits) # this is second layer; minibatch_size by 10 matrix\n",
    "    y_pred = tf.argmax(py_x, dimension=1) # predicting 1 class for each image, minibatch_size by 1 matrix\n",
    "\n",
    "    #define cost\n",
    "    rows_of_cost = tf.nn.softmax_cross_entropy_with_logits(logits, Y, name='rows_of_cost') # cost per image, minibatch_size by 1 matrix\n",
    "    cost = tf.reduce_mean(rows_of_cost, reduction_indices=None, keep_dims=False, name='cost') # average cost over all images. actual loss value\n",
    "\n",
    "    #extract gradients\n",
    "    gradients = tf.gradients(cost, [w], name='gradients')[0] # wow! 1 line to get gradient wrt to complicated cost function\n",
    "\n",
    "    # AdaGrad here\n",
    "    # meta parameters\n",
    "    nSteps = 20\n",
    "    eta = tf.constant(0.5)\n",
    "    #initialize g\n",
    "    sum_g = tf.Variable(tf.ones(weight_shape, dtype=tf.float32)  * 1.0e-3, name='g') #The 1e-3 is to prevent division by zero\n",
    "    sum_g_updater = sum_g.assign(sum_g + tf.square(gradients))\n",
    "    w_updater = w.assign(w - eta * gradients / tf.sqrt(sum_g))\n",
    "    \n",
    "    # summary writers\n",
    "    summary1 = tf.scalar_summary(\"Cost over time\", cost) \n",
    "    summary2 = tf.histogram_summary('Weights over time', w)\n",
    "    merged = tf.merge_summary([summary1, summary2]) \n",
    "    \n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    writer = tf.train.SummaryWriter('logs/',graph=sess.graph)\n",
    "    miniBatchSize = 40\n",
    "    startEnd = zip(range(0, len(xTrain), miniBatchSize), range(miniBatchSize, len(xTrain) + 1, miniBatchSize))\n",
    "    costList = []\n",
    "    nPasses = 30\n",
    "    iteration = 0\n",
    "    for iPass in range(nPasses):\n",
    "        for (s, e) in startEnd:\n",
    "            costVal, _, weight, tbSummary = sess.run([cost, sum_g_updater, w_updater, merged], feed_dict={X: xTrain[s:e,], Y: yTrain[s:e]})\n",
    "            # When trainW is called, it will return the updated weights\n",
    "            writer.add_summary(tbSummary, iteration)\n",
    "            iteration += 1\n",
    "            costList.append(costVal)\n",
    "        if iPass % 5 == 0: \n",
    "            testResult = sess.run([y_pred], feed_dict={X:xTest})\n",
    "            print iPass, np.mean(np.argmax(yTest, axis=1) == testResult) #accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
