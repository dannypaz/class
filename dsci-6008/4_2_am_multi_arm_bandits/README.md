Multi-arm bandits
----

__Introductory__:

- [Fundamentals of learning: the exploration-exploitation trade-off](http://www.tomstafford.staff.shef.ac.uk/?p=48)

__Required__:

- [Beer bandit](http://blog.yhat.com/posts/the-beer-bandit.html)
- [20 lines of code that will beat A/B testing every time](http://stevehanov.ca/blog/index.php?id=132)
- [Efficient experimentation and the multi-armed bandit](http://iosband.github.io/2015/07/19/Efficient-experimentation-and-multi-armed-bandits.html)
- [Multi-Armed Bandits](http://blog.thedataincubator.com/2016/07/multi-armed-bandits-2/)

__Optional__:

- [Python library for Multi-Armed Bandits](https://github.com/bgalbraith/bandits)
- [Multi-Armed Bandits](https://dataorigami.net/blogs/napkin-folding/79031811-multi-armed-bandits) 
- [Adversarial Bandits](http://banditalgs.com/2016/10/01/adversarial-bandits/)

__Challenge__:

- "Taking the Human Out of the Loop: A Review of Bayesian Optimization" in readings folder
- [The Contextual Bandits Problem: A New, Fast, and Simple Algorithm from Microsoft Research](https://www.youtube.com/watch?v=gzxRDw3lXv8)
- [Bandit Algorithms for Website Optimization](http://shop.oreilly.com/product/0636920027393.do)
- [sigopt blog](https://blog.sigopt.com/)