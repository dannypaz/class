RAT: Review
----
Individual Name: ___________________  
Team Names: _____________ &nbsp;&nbsp;&nbsp; _____________ &nbsp;&nbsp;&nbsp; _____________ &nbsp;&nbsp; _____________ &nbsp;&nbsp;&nbsp; _____________

1) How does the creation of probability function differ between discrete and continuous random  variables?

2) How does the creation of cumulative distribution function differ between discrete and continuous random  variables?

3) What is the __empirical__ cumulative distribution function? (HINT: Draw one)

4) As simply as possible, what can a Kalman Filter do? (HINT: It should be ~5 words)

5) Explain the connection between Expectation–Maximization and Kalman Filters:

6) Write the formula for Shannon Entropy:

7) <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Toki_pona.svg/100px-Toki_pona.svg.png" width="10"/> Toki Pona language has 120 __total words__. Does Toki Pona have more or less entropy than English at the word level?

__Challenge__ Calculate the maximum of entropy of Toki Pona at the word level:

__Triple Dog Dare Challenge__ Calculate the maximum of entropy of English words:

<br>
----
__Optional__:

You're about to get on a plane to Seattle for a job interview at Amazon. You want to know if you should bring an umbrella. You know that it rains in Seattle about 25% of the time.

You text your 3 friends who live there and ask each one independently if it's raining. Each of your friends has a 2/3 chance of telling you the truth and a 1/3 chance of messing with you by lying. 

All 3 friends text you: ☔, ☔, ☔

Given what your friends texted, what is the probability that it's actually raining in Seattle? 